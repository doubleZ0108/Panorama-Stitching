{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from  matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_dir = '../img/test/'\n",
    "files = glob.glob(imgs_dir + 'in-*.*g')   # list of matching file paths\n",
    "files = sorted(files)\n",
    "\n",
    "imgs = [np.array(Image.open(files[i])) for i in range(len(files))]\n",
    "\n",
    "factor = -0.5\n",
    "shift = [imgs[0].shape[1] // (3 + factor)]*(len(imgs)-1)      # overlap range(hyper parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select the \"best\" image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getBestImgIndex(imgs):\n",
    "    best_index = 0\n",
    "    best_value = 255\n",
    "    for index, img in enumerate(imgs):\n",
    "        current_mean = np.array([np.mean(img[:,:,0]), np.mean(img[:,:,1]), np.mean(img[:,:,2])])    # average for three channels\n",
    "        diff = np.max(current_mean) - np.min(current_mean)  # difference of three channels\n",
    "        if diff < best_value:       # choose the best(lowest)\n",
    "            best_index = index\n",
    "            best_value = diff\n",
    "    return best_index\n",
    "best_img_index = getBestImgIndex(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## color correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8fa889a485bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mimgs_corrected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorCorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_img_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8fa889a485bf>\u001b[0m in \u001b[0;36mcolorCorrection\u001b[0;34m(images_temp, shift, bestIndex, gamma)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "def colorCorrection(images_temp, shift, bestIndex, gamma=2.2):      # set gamma to 2.2 by paper\n",
    "    alpha = np.ones((3, len(images_temp)))\n",
    "\n",
    "    # compute light averages in the overlap area by linearizing the gamma-corrected RGB values\n",
    "    for rightBorder in range(bestIndex+1, len(images_temp)):\n",
    "        for i in range(bestIndex+1, rightBorder+1):\n",
    "            I = images_temp[i]\n",
    "            J = images_temp[i-1]\n",
    "            overlap = I.shape[1] - shift[i-1]\n",
    "            for channel in range(3):\n",
    "                alpha[channel, i] = np.sum(np.power(J[:,-overlap-1:,channel], gamma))/np.sum(np.power(I[:,0:overlap+1,channel],gamma))  # derivative\n",
    "\n",
    "        G = np.sum(alpha, 1)/np.sum(np.square(alpha), 1)\n",
    "        \n",
    "        for i in range(bestIndex+1, rightBorder+1):\n",
    "            for channel in range(3):\n",
    "                images_temp[i][:,:,channel] = np.power(G[channel] * alpha[channel, i], 1.0/gamma) * images_temp[i][:,:,channel]     # perform using correction coefficients and the global adjustment\n",
    "                \n",
    "    for leftBorder in range(bestIndex-1, -1, -1):\n",
    "        for i in range(bestIndex-1, leftBorder-1, -1):\n",
    "            I = images_temp[i]\n",
    "            J = images_temp[i+1]\n",
    "            overlap = I.shape[1] - shift[i-1]\n",
    "            for channel in range(3):\n",
    "                alpha[channel, i] = np.sum(np.power(J[:,0:overlap+1,channel], gamma))/np.sum(np.power(I[:,-overlap-1:,channel],gamma))\n",
    "\n",
    "        G = np.sum(alpha, 1)/np.sum(np.square(alpha), 1)\n",
    "        \n",
    "        for i in range(bestIndex-1, leftBorder-1, -1):\n",
    "            for channel in range(3):\n",
    "                images_temp[i][:,:,channel] = np.power(G[channel] * alpha[channel, i], 1.0/gamma) * images_temp[i][:,:,channel]\n",
    "    return images_temp\n",
    "\n",
    "imgs_corrected = colorCorrection(imgs, shift, best_img_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimal seam finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcErrorSurface(panorama, curr_img, overlap, channel):\n",
    "    left = panorama[:, -overlap-1:, channel]\n",
    "    right = curr_img[:, 0:overlap+1, channel]\n",
    "    return np.square(left - right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSeam(e):\n",
    "    E = np.zeros(e.shape)   # cumulative minimum squared difference\n",
    "    E[0,:] = e[0,:]\n",
    "    # dynamic programming\n",
    "    for h in range(1, e.shape[0]):\n",
    "        for w in range(0, e.shape[1]):\n",
    "            if w == 0:\n",
    "                cost = min(E[h-1, w], E[h-1, w+1])\n",
    "            elif w == e.shape[1]-1:\n",
    "                cost = min(E[h-1, w-1], E[h-1, w])\n",
    "            else:\n",
    "                cost = min(E[h-1, w-1], E[h-1, w], E[h-1, w+1])\n",
    "            E[h,w] = e[h,w] + cost\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSeamPath(E, e):\n",
    "    h = e.shape[0]\n",
    "    path = np.zeros((h, 1))\n",
    "    idx = np.argmin(E[h-1, :])\n",
    "    path[h-1] = idx\n",
    "    for h in range(e.shape[0]-2,-1,-1):     # tracking back the paths with a minimal cost from bottom to top\n",
    "        w = int(path[h+1][0])\n",
    "        if w > 0 and E[h, w-1] == E[h+1, w]-e[h+1, w]:\n",
    "            path[h] = w-1\n",
    "        elif w < e.shape[1] - 1 and E[h, w+1] == E[h+1, w]-e[h+1, w]:\n",
    "            path[h] = w+1\n",
    "        else:\n",
    "            path[h] = w\n",
    "\n",
    "    path[path==0] = 1\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchImage(panorama, curr_img, path, overlap):\n",
    "    n = 1\n",
    "    bound_threshold = 15;\n",
    "    \n",
    "    tmp = np.zeros((0,panorama.shape[1] + curr_img.shape[1] - overlap,3)).astype('float64')\n",
    "    for h in range(0, panorama.shape[0]):\n",
    "        A = np.expand_dims(panorama[h, 0:-(overlap-int(path[h][0])+1), :], axis=0)\n",
    "        B = np.expand_dims(curr_img[h, int(path[h][0])-1:, :], axis = 0)\n",
    "        ZA = np.concatenate((np.expand_dims(panorama[h,:,:],axis=0), np.zeros((A.shape[0],panorama.shape[1] + curr_img.shape[1] - overlap-np.expand_dims(panorama[h,:,:],axis=0).shape[1],3))), axis=1)\n",
    "        ZB = np.concatenate((np.expand_dims(panorama[h,0:panorama.shape[1] + curr_img.shape[1] - overlap-np.expand_dims(curr_img[h,:,:],axis=0).shape[1],:], axis=0), np.expand_dims(curr_img[h,:,:],axis=0)), axis=1)\n",
    "\n",
    "        filt_A = np.ones((1, A.shape[1]-bound_threshold))\n",
    "        grad = np.expand_dims(np.linspace(1, 0, 2*bound_threshold+1, endpoint=True), axis = 0)\n",
    "        filt_B = np.zeros((1, B.shape[1]-bound_threshold))\n",
    "        blender = np.concatenate((filt_A, grad, filt_B), axis=1)\n",
    "        Z = (blender[:, 0:ZA.shape[1]].T*ZA.T).T + ((1-blender[:, 0:ZB.shape[1]]).T*ZB.T).T\n",
    "        \n",
    "        tmp = np.concatenate((tmp,Z))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'imgs_corrected' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-44cd1fdf550a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpanorama\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_corrected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_corrected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcurr_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_corrected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# get the channel with the largest mean variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs_corrected' is not defined"
     ]
    }
   ],
   "source": [
    "panorama = imgs_corrected[0]\n",
    "for i in range(1, len(imgs_corrected)):\n",
    "    curr_img = imgs_corrected[i]\n",
    "    channel = np.argmax([np.var(curr_img[:,:,0]), np.var(curr_img[:,:,1]), np.var(curr_img[:,:,2])])       # get the channel with the largest mean variance\n",
    "\n",
    "    overlap = curr_img.shape[1] - shift[i-1]\n",
    "\n",
    "    error_surface = calcErrorSurface(panorama, curr_img, overlap, channel)\n",
    "\n",
    "    E = calcSeam(error_surface)\n",
    "\n",
    "    path = calcSeamPath(E, error_surface)\n",
    "\n",
    "    panorama = stitchImage(panorama, curr_img, path, overlap)\n",
    "\n",
    "result = np.array(255*panorama/np.max(panorama)).astype('uint8')\n",
    "plt.figure()\n",
    "plt.imshow(result)\n",
    "imageio.imwrite(imgs_dir+'output.png', np.array(255*panorama/np.max(panorama)).astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit59519ea431e349119ede460a53d16aed",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}